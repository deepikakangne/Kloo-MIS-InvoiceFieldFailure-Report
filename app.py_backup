import os
import logging
import json
import mysql.connector
import pandas as pd
from datetime import datetime
from dotenv import load_dotenv
from utils.db_utils import close_connection
from utils.utils import get_db_password
import boto3
from botocore.exceptions import ClientError
from email.mime.multipart import MIMEMultipart
from email.mime.text import MIMEText

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Load environment variables
load_dotenv()

# Environment variables
DB_USER = os.getenv('DB_USERNAME')
DB_PASSWORD = os.getenv('DB_PASSWORD')
DB_HOST = os.getenv('DB_HOST')
DB_NAME = os.getenv('DB_DATABASE')
DB_PORT = int(os.getenv('DB_PORT'))
AWS_ACCESS_KEY_ID = os.getenv('AWS_ACCESS_KEYID')
AWS_SECRET_ACCESS_KEY = os.getenv('AWS_SECRET_ACCESSKEY')
AWS_REGION = os.getenv('AWS_REGION')
S3_BUCKET_NAME = 'kloo-mis-transaction'

def write_to_excel(query, conn, chunksize, file_path):
    logger.info("Starting to write data to Excel.")
    with pd.ExcelWriter(file_path, engine='openpyxl') as writer:
        start_row = 0
        for i, df_chunk in enumerate(pd.read_sql_query(query, conn, chunksize=chunksize)):
            logger.info(f"Chunk {i + 1} data:\n{df_chunk.head()}")  # Print the first few rows of the chunk
            if i == 0:
                df_chunk.to_excel(writer, sheet_name='DATA', index=False, startrow=start_row)
            else:
                start_row = i * chunksize + 1
                df_chunk.to_excel(writer, sheet_name='DATA', index=False, startrow=start_row, header=False)
            logger.info(f"Written chunk {i + 1} to Excel.")
    logger.info("Finished writing data to Excel.")

def upload_to_s3(file_path, s3_bucket, s3_key):
    s3_client = boto3.client('s3', aws_access_key_id=AWS_ACCESS_KEY_ID, aws_secret_access_key=AWS_SECRET_ACCESS_KEY, region_name=AWS_REGION)

    try:
        s3_client.upload_file(file_path, s3_bucket, s3_key)
        logger.info(f"File uploaded successfully to S3 bucket {s3_bucket} under {s3_key}")
    except ClientError as e:
        logger.error(f"Failed to upload file to S3: {e}")
        raise

def generate_presigned_url(s3_bucket, s3_key, expiration=7200):
    s3_client = boto3.client('s3', aws_access_key_id=AWS_ACCESS_KEY_ID, aws_secret_access_key=AWS_SECRET_ACCESS_KEY, region_name=AWS_REGION)
    
    try:
        response = s3_client.generate_presigned_url('get_object', Params={'Bucket': s3_bucket, 'Key': s3_key}, ExpiresIn=expiration)
        logger.info(f"Generated presigned URL: {response}")
        return response
    except ClientError as e:
        logger.error(f"Failed to generate presigned URL: {e}")
        raise

def send_email_via_ses(sender_email, recipient_emails, subject, body_text, presigned_url, aws_region=AWS_REGION):
    ses_client = boto3.client('ses', region_name=aws_region)
    
    # Create a MIME message
    msg = MIMEMultipart()
    msg['Subject'] = subject
    msg['From'] = f'Kloo <{sender_email}>'
    msg['To'] = ", ".join(recipient_emails)
    
    # Add body text to the email
    body = MIMEText(f'{body_text}\n\nYou can download the file using the following link:\n{presigned_url}', 'plain')
    msg.attach(body)
    
    # Send the email via SES
    try:
        response = ses_client.send_raw_email(
            Source=sender_email,
            Destinations=recipient_emails,
            RawMessage={
                'Data': msg.as_string(),
            }
        )
        logger.info("Email sent successfully!")
        return response
    except ClientError as e:
        logger.error(f"Failed to send email via SES: {e}")
        raise

def generate_report_and_upload_to_s3():
    conn = None
    try:
        logger.info("Environment variables loaded.")

        conn = mysql.connector.connect(
            user=DB_USER,
            password=DB_PASSWORD,
            host=DB_HOST,
            database=DB_NAME,
            port=DB_PORT
        )
        logger.info("Database connection established.")

        query = '''SELECT * FROM `all-transactions-report`;'''
        current_date = datetime.now().strftime('%d-%m-%Y')
        chunksize = 200
        file_path = f'/tmp/Kloo-Mis-Transaction_Report_{current_date}.xlsx'

        logger.info("Writing data to Excel file...")
        write_to_excel(query, conn, chunksize, file_path)

        s3_key = f"Kloo-Mis-Transaction_Report_{current_date}.xlsx"
        logger.info(f"Uploading file to S3 bucket {S3_BUCKET_NAME} under {s3_key}...")
        upload_to_s3(file_path, S3_BUCKET_NAME, s3_key)

        # Generate a pre-signed URL for the uploaded file
        presigned_url = generate_presigned_url(S3_BUCKET_NAME, s3_key)

        # Send the email
        sender_email = 'support@getkloo.com'
        recipient_emails = ["deepika.kangne@blenheimchalcot.com","vaibhav.chotaliya@getkloo.com","shrinivas.krishnamurthy@getkloo.com","sven.huckstadt@blenheimchalcot.com","max.kingdon@getkloo.com","tim.baker@getkloo.com","emmanuel.oyemade@getkloo.com","sahil.shaikh@getkloo.com","shahrukh.shaikh@getkloo.com","samarjit.yadav@getkloo.com","atul.kale@getkloo.com,ai@getkloo.com","zeeshan.siddiquie@blenheimchalcot.com","romil.Shah@blenheimchalcot.com","ai@getkloo.com"
    ]
        subject = f'Platform.Getkloo.Com: MIS Report Transactions Order {current_date}'
        body_text = 'Please find the MIS report for transactions at the following link.'

        logger.info("Sending email with the presigned URL...")
        send_email_via_ses(sender_email, recipient_emails, subject, body_text, presigned_url)

        return {
            'statusCode': 200,
        }
    except mysql.connector.Error as err:
        logger.error(f"Database error: {err}")
        return {
            'statusCode': 500,
            'body': json.dumps(f'Database error: {str(err)}')
        }
    except Exception as error:
        logger.error(f"An unexpected error occurred: {error}")
        return {
            'statusCode': 500,
            'body': json.dumps(f'An error occurred: {str(error)}')
        }
    finally:
        if conn:
            close_connection(conn)
            logger.info("Database connection closed.")

if __name__ == "__main__":
    generate_report_and_upload_to_s3()
